{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52196af9-3a43-44ad-a13d-4be0b6124757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('synthetic_dataset.csv')  # Update with the actual path\n",
    "\n",
    "# Assuming the first 1000 samples are for classification (binary target) and the rest are for regression\n",
    "df_class = df.iloc[:1000]  # Classification part\n",
    "df_regress = df.iloc[1000:]  # Regression part\n",
    "\n",
    "# Prepare datasets for classification\n",
    "X_class = df_class.drop('target', axis=1).values\n",
    "y_class = df_class['target'].values.astype('int')  # Ensuring target is integer for classification\n",
    "\n",
    "# Prepare datasets for regression\n",
    "X_regress = df_regress.drop('target', axis=1).values\n",
    "y_regress = df_regress['target'].values\n",
    "\n",
    "# Split datasets\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
    "X_train_regress, X_test_regress, y_train_regress, y_test_regress = train_test_split(X_regress, y_regress, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features for both tasks\n",
    "scaler_class = StandardScaler().fit(X_train_class)\n",
    "X_train_class_scaled = scaler_class.transform(X_train_class)\n",
    "X_test_class_scaled = scaler_class.transform(X_test_class)\n",
    "\n",
    "scaler_regress = StandardScaler().fit(X_train_regress)\n",
    "X_train_regress_scaled = scaler_regress.transform(X_train_regress)\n",
    "X_test_regress_scaled = scaler_regress.transform(X_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c6d8b-fb96-4811-9142-901cf718e2f9",
   "metadata": {},
   "source": [
    "1. Implement MLP to classify the given data set and analyse the performance of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69d64b6-bb22-4e38-832b-6fd429149144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       106\n",
      "           1       0.94      0.97      0.95        94\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.96      0.95       200\n",
      "weighted avg       0.96      0.95      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.01, learning_rate_init=0.001, random_state=42)\n",
    "mlp_classifier.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "y_pred_class = mlp_classifier.predict(X_test_class_scaled)\n",
    "initial_accuracy_mlp = accuracy_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Accuracy:\", initial_accuracy_mlp)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33788b3-7dcc-40ba-bb72-f7b626cf74e0",
   "metadata": {},
   "source": [
    "2. Implement MLP for regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83186263-13b1-4fbf-bf8b-f94897953559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 78.35172959851523\n",
      "R^2 Score: 0.9984617903860581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.01, learning_rate_init=0.001, random_state=42)\n",
    "mlp_regressor.fit(X_train_regress_scaled, y_train_regress)\n",
    "\n",
    "y_pred_regress = mlp_regressor.predict(X_test_regress_scaled)\n",
    "print(\"MSE:\", mean_squared_error(y_test_regress, y_pred_regress))\n",
    "print(\"R^2 Score:\", r2_score(y_test_regress, y_pred_regress))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192226f8-547b-4953-ab95-0e1ba54bde85",
   "metadata": {},
   "source": [
    "3. Improve the performance of the model by adjusting the hyperparameters such as number of hidden nodes, learning rate parameter, momentum etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc97c3d5-c16e-410b-8285-b660e64b39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy for MLP: 0.97\n",
      "New Classification Report for MLP:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       106\n",
      "           1       0.97      0.97      0.97        94\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.97      0.97      0.97       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n",
      "Improvement in MLP Accuracy: 0.015000000000000013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Define a range of potential values for hyperparameters\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # L2 penalty (regularization term) parameter.\n",
    "    'momentum': [0.9, 0.95, 0.99]\n",
    "}\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# Make scorer using accuracy\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_mlp = GridSearchCV(estimator=mlp, param_grid=param_grid_mlp, cv=5, verbose=0, scoring=accuracy_scorer)\n",
    "\n",
    "# Fit the grid search to the data for classification\n",
    "grid_search_mlp.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "# Re-train MLP with the best parameters\n",
    "best_mlp = MLPClassifier(**grid_search_mlp.best_params_, max_iter=1000, random_state=42)\n",
    "best_mlp.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred_class_best = best_mlp.predict(X_test_class_scaled)\n",
    "new_accuracy_mlp = accuracy_score(y_test_class, y_pred_class_best)\n",
    "new_classification_report_mlp = classification_report(y_test_class, y_pred_class_best)\n",
    "\n",
    "print(\"New Accuracy for MLP:\", new_accuracy_mlp)\n",
    "print(\"New Classification Report for MLP:\\n\", new_classification_report_mlp)\n",
    "print(f\"Improvement in MLP Accuracy: {new_accuracy_mlp - initial_accuracy_mlp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7aade-75fb-47ac-89cc-b02c79c006bb",
   "metadata": {},
   "source": [
    "4. Implement SVM to classify the given data set and analyse the performance of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05ef689-8fb1-4663-92ac-eefd436e82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       106\n",
      "           1       0.79      0.80      0.79        94\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.80      0.80      0.80       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svc_classifier.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "y_pred_svc_class = svc_classifier.predict(X_test_class_scaled)\n",
    "initial_accuracy_svc = accuracy_score(y_test_class, y_pred_svc_class)\n",
    "\n",
    "print(\"Accuracy:\", initial_accuracy_svc)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_class, y_pred_svc_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c14ff-87af-4574-a7f2-75bbee3c391a",
   "metadata": {},
   "source": [
    "5. Implement SVM for regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f76a507c-ce94-4bec-9c9a-69eb93380242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04872490986734624\n",
      "R^2 Score: 0.9999990434273094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_regressor = SVR(kernel='linear', C=1.0)\n",
    "svr_regressor.fit(X_train_regress_scaled, y_train_regress)\n",
    "\n",
    "y_pred_svr_regress = svr_regressor.predict(X_test_regress_scaled)\n",
    "print(\"MSE:\", mean_squared_error(y_test_regress, y_pred_svr_regress))\n",
    "print(\"R^2 Score:\", r2_score(y_test_regress, y_pred_svr_regress))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15129118-02e4-40d0-99f8-08660ed74940",
   "metadata": {},
   "source": [
    "6. Improve the performance of the model by adjusting the hyperparameters such as number of hidden nodes, learning rate parameter, momentum etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85699b8d-6c85-4ae2-a000-de3060d9aba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy for SVC: 0.97\n",
      "New Classification Report for SVC:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       106\n",
      "           1       0.95      0.99      0.97        94\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.97      0.97      0.97       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n",
      "Improvement in SVC Accuracy: 0.16499999999999992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "# Initialize the SVC model\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV object for SVC\n",
    "grid_search_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svc, cv=5, verbose=0, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data for classification\n",
    "grid_search_svc.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "# Re-train SVC with the best parameters\n",
    "best_svc = SVC(**grid_search_svc.best_params_, random_state=42)\n",
    "best_svc.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred_svc_best = best_svc.predict(X_test_class_scaled)\n",
    "new_accuracy_svc = accuracy_score(y_test_class, y_pred_svc_best)\n",
    "new_classification_report_svc = classification_report(y_test_class, y_pred_svc_best)\n",
    "\n",
    "print(\"New Accuracy for SVC:\", new_accuracy_svc)\n",
    "print(\"New Classification Report for SVC:\\n\", new_classification_report_svc)\n",
    "print(f\"Improvement in SVC Accuracy: {new_accuracy_svc - initial_accuracy_svc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1efd17f8-a770-4880-8281-e8300f682744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module mlxtend.preprocessing.onehot in mlxtend.preprocessing:\n",
      "\n",
      "NAME\n",
      "    mlxtend.preprocessing.onehot\n",
      "\n",
      "DESCRIPTION\n",
      "    # Sebastian Raschka 2014-2024\n",
      "    # mlxtend Machine Learning Library Extensions\n",
      "    # Author: Sebastian Raschka <sebastianraschka.com>\n",
      "    #\n",
      "    # License: BSD 3 clause\n",
      "\n",
      "FUNCTIONS\n",
      "    one_hot(y, num_labels='auto', dtype='float')\n",
      "        One-hot encoding of class labels\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y : array-like, shape = [n_classlabels]\n",
      "            Python list or numpy array consisting of class labels.\n",
      "        num_labels : int or 'auto'\n",
      "            Number of unique labels in the class label array. Infers the number\n",
      "            of unique labels from the input array if set to 'auto'.\n",
      "        dtype : str\n",
      "            NumPy array type (float, float32, float64) of the output array.\n",
      "        \n",
      "        Returns\n",
      "        ----------\n",
      "        ary : numpy.ndarray, shape = [n_classlabels]\n",
      "            One-hot encoded array, where each sample is represented as\n",
      "            a row vector in the returned array.\n",
      "        \n",
      "        Examples\n",
      "        ----------\n",
      "        For usage examples, please see\n",
      "        https://rasbt.github.io/mlxtend/user_guide/preprocessing/one_hot/\n",
      "\n",
      "FILE\n",
      "    c:\\users\\mehra\\anaconda3\\lib\\site-packages\\mlxtend\\preprocessing\\onehot.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlxtend import preprocessing\n",
    "help(preprocessing.onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c9817-62b1-46bf-8189-e08e295d1328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
